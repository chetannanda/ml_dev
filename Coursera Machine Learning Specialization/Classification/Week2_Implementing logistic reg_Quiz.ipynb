{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook for week 2 quiz\n",
    "### Will be using numpy and pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Amazon product data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SoftPlay Peek-A-Boo Where's Elmo A Children's ...</td>\n",
       "      <td>Very cute interactive book! My son loves this ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumb...   \n",
       "1    Nature's Lullabies Second Year Sticker Calendar   \n",
       "2    Nature's Lullabies Second Year Sticker Calendar   \n",
       "3                        Lamaze Peekaboo, I Love You   \n",
       "4  SoftPlay Peek-A-Boo Where's Elmo A Children's ...   \n",
       "\n",
       "                                              review  rating  sentiment  \n",
       "0  All of my kids have cried non-stop when I trie...       5          1  \n",
       "1  We wanted to get something to keep track of ou...       5          1  \n",
       "2  My daughter had her 1st baby over a year ago. ...       5          1  \n",
       "3  One of baby's first and favorite books, and it...       4          1  \n",
       "4  Very cute interactive book! My son loves this ...       5          1  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = pd.read_csv('amazon_baby_subset.csv')\n",
    "\n",
    "## Print sample data\n",
    "products.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples:  53072\n",
      "Number of positive sample:  26579\n",
      "Number of negative sample:  26493\n"
     ]
    }
   ],
   "source": [
    "### Data exploration \n",
    "print 'Total number of samples: ', len(products)\n",
    "print 'Number of positive sample: ', len(products[products['sentiment'] == 1])\n",
    "print 'Number of negative sample: ', len(products[products['sentiment'] == -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load important words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_words = pd.read_json('important_words.json')\n",
    "important_words = important_words.values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    text = text.translate(None, string.punctuation)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted text:  This isnt an issue \n"
     ]
    }
   ],
   "source": [
    "sample_text = \"This isn't an issue !!!\"\n",
    "print 'Converted text: ', remove_punctuation(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>My daughter had her 1st baby over a year ago S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>One of babys first and favorite books and it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SoftPlay Peek-A-Boo Where's Elmo A Children's ...</td>\n",
       "      <td>Very cute interactive book! My son loves this ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Very cute interactive book My son loves this b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumb...   \n",
       "1    Nature's Lullabies Second Year Sticker Calendar   \n",
       "2    Nature's Lullabies Second Year Sticker Calendar   \n",
       "3                        Lamaze Peekaboo, I Love You   \n",
       "4  SoftPlay Peek-A-Boo Where's Elmo A Children's ...   \n",
       "\n",
       "                                              review  rating  sentiment  \\\n",
       "0  All of my kids have cried non-stop when I trie...       5          1   \n",
       "1  We wanted to get something to keep track of ou...       5          1   \n",
       "2  My daughter had her 1st baby over a year ago. ...       5          1   \n",
       "3  One of baby's first and favorite books, and it...       4          1   \n",
       "4  Very cute interactive book! My son loves this ...       5          1   \n",
       "\n",
       "                                        review_clean  \n",
       "0  All of my kids have cried nonstop when I tried...  \n",
       "1  We wanted to get something to keep track of ou...  \n",
       "2  My daughter had her 1st baby over a year ago S...  \n",
       "3  One of babys first and favorite books and it i...  \n",
       "4  Very cute interactive book My son loves this b...  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Fill all n/a in review column with empty (\"\") string\n",
    "products = products.fillna({'review':''})\n",
    "\n",
    "### Remove punctuation\n",
    "products['review_clean'] = products['review'].apply(remove_punctuation)\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'Bag of Words' text analysis on review_clean column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in important_words:\n",
    "    #print word\n",
    "    products[word] = products['review_clean'].apply(lambda s: s.split().count(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>baby</th>\n",
       "      <th>one</th>\n",
       "      <th>great</th>\n",
       "      <th>love</th>\n",
       "      <th>use</th>\n",
       "      <th>...</th>\n",
       "      <th>seems</th>\n",
       "      <th>picture</th>\n",
       "      <th>completely</th>\n",
       "      <th>wish</th>\n",
       "      <th>buying</th>\n",
       "      <th>babies</th>\n",
       "      <th>won</th>\n",
       "      <th>tub</th>\n",
       "      <th>almost</th>\n",
       "      <th>either</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>My daughter had her 1st baby over a year ago S...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>One of babys first and favorite books and it i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SoftPlay Peek-A-Boo Where's Elmo A Children's ...</td>\n",
       "      <td>Very cute interactive book! My son loves this ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Very cute interactive book My son loves this b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumb...   \n",
       "1    Nature's Lullabies Second Year Sticker Calendar   \n",
       "2    Nature's Lullabies Second Year Sticker Calendar   \n",
       "3                        Lamaze Peekaboo, I Love You   \n",
       "4  SoftPlay Peek-A-Boo Where's Elmo A Children's ...   \n",
       "\n",
       "                                              review  rating  sentiment  \\\n",
       "0  All of my kids have cried non-stop when I trie...       5          1   \n",
       "1  We wanted to get something to keep track of ou...       5          1   \n",
       "2  My daughter had her 1st baby over a year ago. ...       5          1   \n",
       "3  One of baby's first and favorite books, and it...       4          1   \n",
       "4  Very cute interactive book! My son loves this ...       5          1   \n",
       "\n",
       "                                        review_clean  baby  one  great  love  \\\n",
       "0  All of my kids have cried nonstop when I tried...     0    0      1     0   \n",
       "1  We wanted to get something to keep track of ou...     0    0      0     0   \n",
       "2  My daughter had her 1st baby over a year ago S...     1    0      0     0   \n",
       "3  One of babys first and favorite books and it i...     0    0      0     0   \n",
       "4  Very cute interactive book My son loves this b...     0    0      1     0   \n",
       "\n",
       "   use   ...    seems  picture  completely  wish  buying  babies  won  tub  \\\n",
       "0    0   ...        0        0           0     0       0       0    0    0   \n",
       "1    0   ...        0        0           0     0       0       0    0    0   \n",
       "2    0   ...        0        0           0     0       0       0    0    0   \n",
       "3    0   ...        0        0           0     0       0       0    0    0   \n",
       "4    0   ...        0        0           0     0       0       1    0    0   \n",
       "\n",
       "   almost  either  \n",
       "0       0       0  \n",
       "1       0       0  \n",
       "2       0       0  \n",
       "3       0       0  \n",
       "4       0       0  \n",
       "\n",
       "[5 rows x 198 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### After bag of words analysis for important words\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quiz question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of prodict review contains word \"perfect\" : 2955\n"
     ]
    }
   ],
   "source": [
    "print 'Number of prodict review contains word \"perfect\" :', len(products[products['perfect'] > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert data into multidimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(dataframe, features, label):\n",
    "    # Initialize the np array with all ones, the number of columns are +1 \n",
    "    # to accomodate the column for bias feature\n",
    "    matrix_len = len(dataframe)\n",
    "    matrix_width = len(features) + 1\n",
    "    feature_matrix = np.ones((matrix_len, matrix_width))\n",
    "    \n",
    "    print 'Feature matrix size', feature_matrix.shape\n",
    "    i = 1\n",
    "    for feature in features:\n",
    "        feature_matrix[:, i] = dataframe[feature]\n",
    "        i = i +1\n",
    "    return (feature_matrix, dataframe[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix size (53072, 194)\n"
     ]
    }
   ],
   "source": [
    "## Extract the feature matrix\n",
    "feature_matrix, sentiment = get_numpy_data(products, important_words, 'sentiment')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quiz question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of feature in feature_matrix:  194\n"
     ]
    }
   ],
   "source": [
    "print 'Number of feature in feature_matrix: ', feature_matrix.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_probability(feature_matrix, coefficients):\n",
    "    return (1.0 / (1 + np.exp(-1 * np.dot(feature_matrix, coefficients))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_derivative(error, feature):\n",
    "    #print feature\n",
    "    return np.dot(feature, error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log-likelihood is computed using the following formula (see the advanced optional video if you are curious about the derivation of this equation):\n",
    "\n",
    "ℓℓ(w)=∑i=1N((1[yi=+1]−1)w⊺h(wi)−ln(1+exp(−w⊺h(xi))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_likelihood(feature_matrix, sentiment, coefficients):\n",
    "    indicator = (sentiment==+1).values.reshape(-1,1)\n",
    "    scores = np.dot(feature_matrix, coefficients)\n",
    "    lp = np.sum((indicator-1)*scores - np.log(1. + np.exp(-scores)))\n",
    "    return lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "def logistic_regression(feature_matrix, sentiment, initial_coefficients, step_size, max_iter):\n",
    "    coefficients = np.array(initial_coefficients)\n",
    "    itr = 0;\n",
    "    while (itr < max_iter):\n",
    "        predictions = predict_probability(feature_matrix, coefficients)\n",
    "        indicator = (sentiment==+1).values.reshape(-1,1)\n",
    "        \n",
    "        #print 'indicator shape', indicator.shape\n",
    "        #print 'predictions shape', predictions.shape\n",
    "        \n",
    "        error = indicator - predictions\n",
    "\n",
    "        for i in xrange(len(coefficients)):\n",
    "            derivative = feature_derivative(error, feature_matrix[:,i])\n",
    "            coefficients[i] = coefficients[i] + step_size * derivative\n",
    "    \n",
    "        # Checking whether log likelihood is increasing\n",
    "        if itr <= 15 or (itr <= 100 and itr % 10 == 0) or (itr <= 1000 and itr % 100 == 0) \\\n",
    "        or (itr <= 10000 and itr % 1000 == 0) or itr % 10000 == 0:\n",
    "            lp = compute_log_likelihood(feature_matrix, sentiment, coefficients)\n",
    "            print 'iteration %*d: log likelihood of observed labels = %.8f' % \\\n",
    "                (int(np.ceil(np.log10(max_iter))), itr, lp)\n",
    "       \n",
    "        itr = itr +1\n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "initial_coefficients = np.zeros((feature_matrix.shape[1], 1))\n",
    "step_size = 1e-7\n",
    "max_iter = 301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -36780.91768478\n",
      "iteration   1: log likelihood of observed labels = -36775.13434712\n",
      "iteration   2: log likelihood of observed labels = -36769.35713564\n",
      "iteration   3: log likelihood of observed labels = -36763.58603240\n",
      "iteration   4: log likelihood of observed labels = -36757.82101962\n",
      "iteration   5: log likelihood of observed labels = -36752.06207964\n",
      "iteration   6: log likelihood of observed labels = -36746.30919497\n",
      "iteration   7: log likelihood of observed labels = -36740.56234821\n",
      "iteration   8: log likelihood of observed labels = -36734.82152213\n",
      "iteration   9: log likelihood of observed labels = -36729.08669961\n",
      "iteration  10: log likelihood of observed labels = -36723.35786366\n",
      "iteration  11: log likelihood of observed labels = -36717.63499744\n",
      "iteration  12: log likelihood of observed labels = -36711.91808422\n",
      "iteration  13: log likelihood of observed labels = -36706.20710739\n",
      "iteration  14: log likelihood of observed labels = -36700.50205049\n",
      "iteration  15: log likelihood of observed labels = -36694.80289716\n",
      "iteration  20: log likelihood of observed labels = -36666.39512033\n",
      "iteration  30: log likelihood of observed labels = -36610.01327118\n",
      "iteration  40: log likelihood of observed labels = -36554.19728365\n",
      "iteration  50: log likelihood of observed labels = -36498.93316099\n",
      "iteration  60: log likelihood of observed labels = -36444.20783914\n",
      "iteration  70: log likelihood of observed labels = -36390.00909449\n",
      "iteration  80: log likelihood of observed labels = -36336.32546144\n",
      "iteration  90: log likelihood of observed labels = -36283.14615871\n",
      "iteration 100: log likelihood of observed labels = -36230.46102347\n",
      "iteration 200: log likelihood of observed labels = -35728.89418769\n",
      "iteration 300: log likelihood of observed labels = -35268.51212683\n"
     ]
    }
   ],
   "source": [
    "coefficients = logistic_regression(feature_matrix, sentiment, initial_coefficients, step_size, max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive predictions:  25126\n",
      "Number of miss_classifications:  13169.0\n"
     ]
    }
   ],
   "source": [
    "### Scores with estimated coff\n",
    "scores = np.dot(feature_matrix, coefficients)\n",
    "indicies = scores > 0\n",
    "indicies_low = scores <= 0\n",
    "scores[indicies] = 1\n",
    "scores[indicies_low] = -1\n",
    "\n",
    "#print scores.shape\n",
    "#print sentiment.shape\n",
    "#print indicies.shape\n",
    "miss_classifications =  (abs(scores - sentiment.values.reshape(-1,1))).sum() /2\n",
    "\n",
    "print 'Number of positive predictions: ',len(feature_matrix[indicies.flatten()])\n",
    "print 'Number of miss_classifications: ', miss_classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quiz question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy:  0.751865390413\n"
     ]
    }
   ],
   "source": [
    "print 'Model accuracy: ', (len(feature_matrix) - miss_classifications) * 1.0/ len(feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = list(coefficients[1:]) # exclude intercept\n",
    "#print coefficients\n",
    "word_coefficient_tuples = [(word, coefficient) for word, coefficient in zip(important_words, coefficients)]\n",
    "word_coefficient_tuples = sorted(word_coefficient_tuples, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'great', array([ 0.06654608])),\n",
       " (u'love', array([ 0.06589076])),\n",
       " (u'easy', array([ 0.06479459])),\n",
       " (u'little', array([ 0.04543563])),\n",
       " (u'loves', array([ 0.0449764])),\n",
       " (u'well', array([ 0.030135])),\n",
       " (u'perfect', array([ 0.02973994])),\n",
       " (u'old', array([ 0.02007754])),\n",
       " (u'nice', array([ 0.01840871])),\n",
       " (u'daughter', array([ 0.0177032])),\n",
       " (u'soft', array([ 0.01757027])),\n",
       " (u'fits', array([ 0.01688247])),\n",
       " (u'happy', array([ 0.0168053])),\n",
       " (u'baby', array([ 0.0155657])),\n",
       " (u'recommend', array([ 0.01540845])),\n",
       " (u'also', array([ 0.0152162])),\n",
       " (u'best', array([ 0.01499179])),\n",
       " (u'comfortable', array([ 0.01325399])),\n",
       " (u'car', array([ 0.01268594])),\n",
       " (u'clean', array([ 0.01201817])),\n",
       " (u'son', array([ 0.01194482])),\n",
       " (u'bit', array([ 0.01170825])),\n",
       " (u'works', array([ 0.01170316])),\n",
       " (u'size', array([ 0.01071597])),\n",
       " (u'stroller', array([ 0.00990916])),\n",
       " (u'room', array([ 0.00978324])),\n",
       " (u'price', array([ 0.00957273])),\n",
       " (u'play', array([ 0.00917843])),\n",
       " (u'easily', array([ 0.00903282])),\n",
       " (u'kids', array([ 0.00858284])),\n",
       " (u'still', array([ 0.00826467])),\n",
       " (u'lot', array([ 0.00799939])),\n",
       " (u'around', array([ 0.00750892])),\n",
       " (u'need', array([ 0.00717191])),\n",
       " (u'take', array([ 0.00671012])),\n",
       " (u'keep', array([ 0.00643767])),\n",
       " (u'crib', array([ 0.0060028])),\n",
       " (u'without', array([ 0.00592354])),\n",
       " (u'year', array([ 0.0057332])),\n",
       " (u'set', array([ 0.00567479])),\n",
       " (u'cute', array([ 0.00553751])),\n",
       " (u'use', array([ 0.00501744])),\n",
       " (u'big', array([ 0.00460662])),\n",
       " (u'diaper', array([ 0.00427938])),\n",
       " (u'wish', array([ 0.00402038])),\n",
       " (u'seat', array([ 0.00398353])),\n",
       " (u'though', array([ 0.0033449])),\n",
       " (u'every', array([ 0.00308148])),\n",
       " (u'enough', array([ 0.00306786])),\n",
       " (u'able', array([ 0.00298031])),\n",
       " (u'bag', array([ 0.00286179])),\n",
       " (u'babies', array([ 0.00285819])),\n",
       " (u'seems', array([ 0.00281533])),\n",
       " (u'night', array([ 0.00280826])),\n",
       " (u'good', array([ 0.0027682])),\n",
       " (u'many', array([ 0.00264661])),\n",
       " (u'makes', array([ 0.00231349])),\n",
       " (u'pretty', array([ 0.00223639])),\n",
       " (u'long', array([ 0.00218724])),\n",
       " (u'think', array([ 0.00174563])),\n",
       " (u'toy', array([ 0.00172307])),\n",
       " (u'since', array([ 0.00155479])),\n",
       " (u'looking', array([ 0.00153471])),\n",
       " (u'us', array([ 0.00151368])),\n",
       " (u'purchase', array([ 0.00122258])),\n",
       " (u'put', array([ 0.00089924])),\n",
       " (u'cover', array([ 0.00082925])),\n",
       " (u'used', array([ 0.00061013])),\n",
       " (u'found', array([ 0.00041209])),\n",
       " (u'really', array([ 0.00027259])),\n",
       " (u'won', array([ 0.00011989])),\n",
       " (u'go', array([  9.91666827e-05])),\n",
       " (u'looks', array([  1.36699286e-05])),\n",
       " (u'high', array([-0.00018649])),\n",
       " (u'day', array([-0.00018857])),\n",
       " (u'bottles', array([-0.00033567])),\n",
       " (u'chair', array([-0.00051596])),\n",
       " (u'using', array([-0.00065735])),\n",
       " (u'side', array([-0.00086139])),\n",
       " (u'worth', array([-0.00097622])),\n",
       " (u'almost', array([-0.00114494])),\n",
       " (u'hold', array([-0.00124762])),\n",
       " (u'months', array([-0.0013622])),\n",
       " (u'look', array([-0.00164575])),\n",
       " (u'sure', array([-0.00166895])),\n",
       " (u'find', array([-0.001942])),\n",
       " (u'amazon', array([-0.00197321])),\n",
       " (u'month', array([-0.00220318])),\n",
       " (u'getting', array([-0.00222034])),\n",
       " (u'come', array([-0.00247806])),\n",
       " (u'second', array([-0.00301867])),\n",
       " (u'head', array([-0.00302579])),\n",
       " (u'small', array([-0.00305345])),\n",
       " (u'place', array([-0.00331888])),\n",
       " (u'together', array([-0.00341331])),\n",
       " (u'want', array([-0.00348089])),\n",
       " (u'like', array([-0.00350488])),\n",
       " (u'give', array([-0.00350985])),\n",
       " (u'say', array([-0.00373694])),\n",
       " (u'wanted', array([-0.00381416])),\n",
       " (u'know', array([-0.00407497])),\n",
       " (u'took', array([-0.00426644])),\n",
       " (u'much', array([-0.004397])),\n",
       " (u'see', array([-0.00465974])),\n",
       " (u'purchased', array([-0.00478991])),\n",
       " (u'fit', array([-0.0047958])),\n",
       " (u'gate', array([-0.00501292])),\n",
       " (u'bottle', array([-0.00504082])),\n",
       " (u'different', array([-0.00504128])),\n",
       " (u'came', array([-0.00510116])),\n",
       " (u'however', array([-0.00510288])),\n",
       " (u'make', array([-0.00520588])),\n",
       " (u'new', array([-0.00528786])),\n",
       " (u'buying', array([-0.005443])),\n",
       " (u'last', array([-0.00547016])),\n",
       " (u'actually', array([-0.00560573])),\n",
       " (u'less', array([-0.00565499])),\n",
       " (u'child', array([-0.00608714])),\n",
       " (u'started', array([-0.00626283])),\n",
       " (u'instead', array([-0.00630013])),\n",
       " (u'water', array([-0.00630054])),\n",
       " (u'maybe', array([-0.00640099])),\n",
       " (u'problem', array([-0.00640959])),\n",
       " (u'right', array([-0.00641369])),\n",
       " (u'tub', array([-0.00647588])),\n",
       " (u'said', array([-0.0067629])),\n",
       " (u'went', array([-0.0068705])),\n",
       " (u'quality', array([-0.00691011])),\n",
       " (u'pump', array([-0.00695287])),\n",
       " (u'top', array([-0.00700792])),\n",
       " (u'part', array([-0.00704172])),\n",
       " (u'ordered', array([-0.00707573])),\n",
       " (u'either', array([-0.00709206])),\n",
       " (u'bottom', array([-0.00722099])),\n",
       " (u'anything', array([-0.0072242])),\n",
       " (u'made', array([-0.00735346])),\n",
       " (u'weeks', array([-0.00737263])),\n",
       " (u'design', array([-0.00773229])),\n",
       " (u'times', array([-0.00776419])),\n",
       " (u'picture', array([-0.0081015])),\n",
       " (u'away', array([-0.00831783])),\n",
       " (u'one', array([-0.00850205])),\n",
       " (u'milk', array([-0.00893573])),\n",
       " (u'stay', array([-0.00906653])),\n",
       " (u'open', array([-0.00912049])),\n",
       " (u'cup', array([-0.00925914])),\n",
       " (u'worked', array([-0.00931521])),\n",
       " (u'trying', array([-0.00987425])),\n",
       " (u'completely', array([-0.01000621])),\n",
       " (u'got', array([-0.01014766])),\n",
       " (u'difficult', array([-0.0102192])),\n",
       " (u'piece', array([-0.01028263])),\n",
       " (u'two', array([-0.0105768])),\n",
       " (u'box', array([-0.01066913])),\n",
       " (u'going', array([-0.01077094])),\n",
       " (u'try', array([-0.01091879])),\n",
       " (u'another', array([-0.01095091])),\n",
       " (u'unit', array([-0.01152305])),\n",
       " (u'working', array([-0.01189506])),\n",
       " (u'idea', array([-0.01210103])),\n",
       " (u'bought', array([-0.01217064])),\n",
       " (u'company', array([-0.01250639])),\n",
       " (u'received', array([-0.01260519])),\n",
       " (u'bad', array([-0.01275457])),\n",
       " (u'something', array([-0.01280884])),\n",
       " (u'never', array([-0.01296905])),\n",
       " (u'first', array([-0.01321348])),\n",
       " (u'hard', array([-0.01375668])),\n",
       " (u'thing', array([-0.01386873])),\n",
       " (u'cheap', array([-0.01470983])),\n",
       " (u'reviews', array([-0.01486632])),\n",
       " (u'plastic', array([-0.01497704])),\n",
       " (u'better', array([-0.01504066])),\n",
       " (u'broke', array([-0.0155377])),\n",
       " (u'returned', array([-0.0160018])),\n",
       " (u'item', array([-0.01713787])),\n",
       " (u'buy', array([-0.01773754])),\n",
       " (u'time', array([-0.01824619])),\n",
       " (u'way', array([-0.01835946])),\n",
       " (u'tried', array([-0.01870237])),\n",
       " (u'could', array([-0.01984626])),\n",
       " (u'thought', array([-0.02139435])),\n",
       " (u'waste', array([-0.02404275])),\n",
       " (u'monitor', array([-0.0244821])),\n",
       " (u'return', array([-0.02659278])),\n",
       " (u'back', array([-0.0277427])),\n",
       " (u'get', array([-0.02871155])),\n",
       " (u'disappointed', array([-0.02897898])),\n",
       " (u'even', array([-0.03005125])),\n",
       " (u'work', array([-0.03306952])),\n",
       " (u'money', array([-0.03898204])),\n",
       " (u'product', array([-0.04151103])),\n",
       " (u'would', array([-0.05386015]))]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_coefficient_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ten \"most positive\" words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(u'great', array([ 0.06654608])),\n",
       " (u'love', array([ 0.06589076])),\n",
       " (u'easy', array([ 0.06479459])),\n",
       " (u'little', array([ 0.04543563])),\n",
       " (u'loves', array([ 0.0449764])),\n",
       " (u'well', array([ 0.030135])),\n",
       " (u'perfect', array([ 0.02973994])),\n",
       " (u'old', array([ 0.02007754])),\n",
       " (u'nice', array([ 0.01840871])),\n",
       " (u'daughter', array([ 0.0177032]))]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print 'Ten \"most positive\" words'\n",
    "word_coefficient_tuples[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ten \"most negative\" words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(u'waste', array([-0.02404275])),\n",
       " (u'monitor', array([-0.0244821])),\n",
       " (u'return', array([-0.02659278])),\n",
       " (u'back', array([-0.0277427])),\n",
       " (u'get', array([-0.02871155])),\n",
       " (u'disappointed', array([-0.02897898])),\n",
       " (u'even', array([-0.03005125])),\n",
       " (u'work', array([-0.03306952])),\n",
       " (u'money', array([-0.03898204])),\n",
       " (u'product', array([-0.04151103]))]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print 'Ten \"most negative\" words'\n",
    "word_coefficient_tuples[-11:-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
